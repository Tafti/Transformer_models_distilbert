{
  "best_global_step": 750,
  "best_metric": 0.938,
  "best_model_checkpoint": null,
  "epoch": 6.4,
  "eval_steps": 250,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 3.1933326721191406,
      "learning_rate": 9.91e-06,
      "loss": 0.0975,
      "step": 10
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.61968994140625,
      "learning_rate": 9.810000000000001e-06,
      "loss": 0.1075,
      "step": 20
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.909808874130249,
      "learning_rate": 9.71e-06,
      "loss": 0.1165,
      "step": 30
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.576655387878418,
      "learning_rate": 9.610000000000001e-06,
      "loss": 0.1164,
      "step": 40
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.967935562133789,
      "learning_rate": 9.51e-06,
      "loss": 0.0972,
      "step": 50
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.067516326904297,
      "learning_rate": 9.41e-06,
      "loss": 0.1243,
      "step": 60
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.830482244491577,
      "learning_rate": 9.31e-06,
      "loss": 0.1122,
      "step": 70
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.666863441467285,
      "learning_rate": 9.210000000000002e-06,
      "loss": 0.1342,
      "step": 80
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.4768989086151123,
      "learning_rate": 9.110000000000001e-06,
      "loss": 0.0965,
      "step": 90
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.272089719772339,
      "learning_rate": 9.01e-06,
      "loss": 0.11,
      "step": 100
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.4462075233459473,
      "learning_rate": 8.910000000000001e-06,
      "loss": 0.1177,
      "step": 110
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.620793342590332,
      "learning_rate": 8.81e-06,
      "loss": 0.1056,
      "step": 120
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.5253825187683105,
      "learning_rate": 8.710000000000001e-06,
      "loss": 0.0948,
      "step": 130
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.1658525466918945,
      "learning_rate": 8.61e-06,
      "loss": 0.0818,
      "step": 140
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.5200157165527344,
      "learning_rate": 8.51e-06,
      "loss": 0.1122,
      "step": 150
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.2934916019439697,
      "learning_rate": 8.41e-06,
      "loss": 0.0946,
      "step": 160
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 4.128683567047119,
      "learning_rate": 8.31e-06,
      "loss": 0.1043,
      "step": 170
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.3365628719329834,
      "learning_rate": 8.210000000000001e-06,
      "loss": 0.0873,
      "step": 180
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.2884066104888916,
      "learning_rate": 8.110000000000002e-06,
      "loss": 0.0836,
      "step": 190
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.381037473678589,
      "learning_rate": 8.010000000000001e-06,
      "loss": 0.0823,
      "step": 200
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.8202381134033203,
      "learning_rate": 7.91e-06,
      "loss": 0.1084,
      "step": 210
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.5482351779937744,
      "learning_rate": 7.810000000000001e-06,
      "loss": 0.1088,
      "step": 220
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 7.312739372253418,
      "learning_rate": 7.71e-06,
      "loss": 0.1274,
      "step": 230
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.181586265563965,
      "learning_rate": 7.610000000000001e-06,
      "loss": 0.107,
      "step": 240
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.391988515853882,
      "learning_rate": 7.510000000000001e-06,
      "loss": 0.0873,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.935,
      "eval_f1": 0.9359454329271014,
      "eval_loss": 0.16189312934875488,
      "eval_runtime": 2.2472,
      "eval_samples_per_second": 890.005,
      "eval_steps_per_second": 7.12,
      "step": 250
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.9323227405548096,
      "learning_rate": 7.41e-06,
      "loss": 0.0965,
      "step": 260
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.4119417667388916,
      "learning_rate": 7.31e-06,
      "loss": 0.0882,
      "step": 270
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.9265177249908447,
      "learning_rate": 7.2100000000000004e-06,
      "loss": 0.0741,
      "step": 280
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.1963536739349365,
      "learning_rate": 7.1100000000000005e-06,
      "loss": 0.0787,
      "step": 290
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.8807590007781982,
      "learning_rate": 7.01e-06,
      "loss": 0.085,
      "step": 300
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.4407384395599365,
      "learning_rate": 6.91e-06,
      "loss": 0.0914,
      "step": 310
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.8911151885986328,
      "learning_rate": 6.810000000000001e-06,
      "loss": 0.0778,
      "step": 320
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.329699993133545,
      "learning_rate": 6.710000000000001e-06,
      "loss": 0.0843,
      "step": 330
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.8932007551193237,
      "learning_rate": 6.610000000000001e-06,
      "loss": 0.1031,
      "step": 340
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.380145072937012,
      "learning_rate": 6.51e-06,
      "loss": 0.0719,
      "step": 350
    },
    {
      "epoch": 2.88,
      "grad_norm": 4.496472358703613,
      "learning_rate": 6.4100000000000005e-06,
      "loss": 0.1003,
      "step": 360
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.326022148132324,
      "learning_rate": 6.3100000000000006e-06,
      "loss": 0.0819,
      "step": 370
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.3360595703125,
      "learning_rate": 6.210000000000001e-06,
      "loss": 0.0758,
      "step": 380
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.6186487674713135,
      "learning_rate": 6.110000000000001e-06,
      "loss": 0.0743,
      "step": 390
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.2060601711273193,
      "learning_rate": 6.01e-06,
      "loss": 0.0738,
      "step": 400
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.2719767093658447,
      "learning_rate": 5.91e-06,
      "loss": 0.0627,
      "step": 410
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.335904359817505,
      "learning_rate": 5.81e-06,
      "loss": 0.0813,
      "step": 420
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.5154478549957275,
      "learning_rate": 5.71e-06,
      "loss": 0.0737,
      "step": 430
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.2640492916107178,
      "learning_rate": 5.610000000000001e-06,
      "loss": 0.0796,
      "step": 440
    },
    {
      "epoch": 3.6,
      "grad_norm": 2.991097927093506,
      "learning_rate": 5.510000000000001e-06,
      "loss": 0.0838,
      "step": 450
    },
    {
      "epoch": 3.68,
      "grad_norm": 4.230362415313721,
      "learning_rate": 5.410000000000001e-06,
      "loss": 0.0821,
      "step": 460
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.895582914352417,
      "learning_rate": 5.310000000000001e-06,
      "loss": 0.0925,
      "step": 470
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.417285442352295,
      "learning_rate": 5.210000000000001e-06,
      "loss": 0.0835,
      "step": 480
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.2201104164123535,
      "learning_rate": 5.11e-06,
      "loss": 0.0778,
      "step": 490
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.8598103523254395,
      "learning_rate": 5.01e-06,
      "loss": 0.0691,
      "step": 500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9365,
      "eval_f1": 0.9361577623579794,
      "eval_loss": 0.15545199811458588,
      "eval_runtime": 2.1785,
      "eval_samples_per_second": 918.061,
      "eval_steps_per_second": 7.344,
      "step": 500
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.436537265777588,
      "learning_rate": 4.9100000000000004e-06,
      "loss": 0.0666,
      "step": 510
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.6951539516448975,
      "learning_rate": 4.8100000000000005e-06,
      "loss": 0.0603,
      "step": 520
    },
    {
      "epoch": 4.24,
      "grad_norm": 3.025651693344116,
      "learning_rate": 4.71e-06,
      "loss": 0.0566,
      "step": 530
    },
    {
      "epoch": 4.32,
      "grad_norm": 3.199242353439331,
      "learning_rate": 4.610000000000001e-06,
      "loss": 0.0777,
      "step": 540
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.242357015609741,
      "learning_rate": 4.510000000000001e-06,
      "loss": 0.0807,
      "step": 550
    },
    {
      "epoch": 4.48,
      "grad_norm": 5.800851821899414,
      "learning_rate": 4.41e-06,
      "loss": 0.079,
      "step": 560
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 4.866488456726074,
      "learning_rate": 4.31e-06,
      "loss": 0.0678,
      "step": 570
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.7127392292022705,
      "learning_rate": 4.21e-06,
      "loss": 0.0687,
      "step": 580
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.078040361404419,
      "learning_rate": 4.1100000000000005e-06,
      "loss": 0.0643,
      "step": 590
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.512104034423828,
      "learning_rate": 4.0100000000000006e-06,
      "loss": 0.0714,
      "step": 600
    },
    {
      "epoch": 4.88,
      "grad_norm": 7.057509422302246,
      "learning_rate": 3.910000000000001e-06,
      "loss": 0.0886,
      "step": 610
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.027111053466797,
      "learning_rate": 3.8100000000000004e-06,
      "loss": 0.0554,
      "step": 620
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.9915387630462646,
      "learning_rate": 3.7100000000000005e-06,
      "loss": 0.0769,
      "step": 630
    },
    {
      "epoch": 5.12,
      "grad_norm": 3.0450327396392822,
      "learning_rate": 3.61e-06,
      "loss": 0.0604,
      "step": 640
    },
    {
      "epoch": 5.2,
      "grad_norm": 4.996084690093994,
      "learning_rate": 3.5100000000000003e-06,
      "loss": 0.068,
      "step": 650
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.8920178413391113,
      "learning_rate": 3.4100000000000004e-06,
      "loss": 0.0666,
      "step": 660
    },
    {
      "epoch": 5.36,
      "grad_norm": 2.167879343032837,
      "learning_rate": 3.3100000000000005e-06,
      "loss": 0.0498,
      "step": 670
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.9006844758987427,
      "learning_rate": 3.21e-06,
      "loss": 0.068,
      "step": 680
    },
    {
      "epoch": 5.52,
      "grad_norm": 3.986393690109253,
      "learning_rate": 3.1100000000000003e-06,
      "loss": 0.0643,
      "step": 690
    },
    {
      "epoch": 5.6,
      "grad_norm": 3.1769509315490723,
      "learning_rate": 3.01e-06,
      "loss": 0.0628,
      "step": 700
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.8702746629714966,
      "learning_rate": 2.91e-06,
      "loss": 0.0564,
      "step": 710
    },
    {
      "epoch": 5.76,
      "grad_norm": 2.542865037918091,
      "learning_rate": 2.8100000000000006e-06,
      "loss": 0.093,
      "step": 720
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.5694327354431152,
      "learning_rate": 2.7100000000000003e-06,
      "loss": 0.0618,
      "step": 730
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.839778184890747,
      "learning_rate": 2.6100000000000004e-06,
      "loss": 0.0637,
      "step": 740
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.9487411975860596,
      "learning_rate": 2.51e-06,
      "loss": 0.0642,
      "step": 750
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.938,
      "eval_f1": 0.9383771970960857,
      "eval_loss": 0.15851788222789764,
      "eval_runtime": 2.2611,
      "eval_samples_per_second": 884.534,
      "eval_steps_per_second": 7.076,
      "step": 750
    },
    {
      "epoch": 6.08,
      "grad_norm": 2.702444076538086,
      "learning_rate": 2.4100000000000002e-06,
      "loss": 0.0724,
      "step": 760
    },
    {
      "epoch": 6.16,
      "grad_norm": 4.340670585632324,
      "learning_rate": 2.3100000000000003e-06,
      "loss": 0.0571,
      "step": 770
    },
    {
      "epoch": 6.24,
      "grad_norm": 2.5797457695007324,
      "learning_rate": 2.21e-06,
      "loss": 0.0526,
      "step": 780
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.0616931915283203,
      "learning_rate": 2.11e-06,
      "loss": 0.0591,
      "step": 790
    },
    {
      "epoch": 6.4,
      "grad_norm": 3.239609718322754,
      "learning_rate": 2.0100000000000002e-06,
      "loss": 0.0564,
      "step": 800
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 800,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2305097157427200.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
